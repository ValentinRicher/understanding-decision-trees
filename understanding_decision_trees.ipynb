{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "understanding_decision_trees.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ValentinRicher/understanding-decision-trees/blob/master/understanding_decision_trees.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "3VntO0J1APY7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 6- Understanding how the model builds its decision\n",
        "Having a good prediction is interesting but understanding how the model has build its predicting path is essential. <br/>\n",
        "In the following section, we will study the previous given graph step by step for each depth of the graph. <br/>\n",
        "After this section you will be able to :\n",
        "*  decrypt a decision tree\n",
        "*  understand the concept of decision boundary\n",
        "*\n"
      ]
    },
    {
      "metadata": {
        "id": "abCeCXjzAQRd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_lines(depth, lim, node_n=0):\n",
        "  '''\n",
        "  Fetches the lines corresponding to the decision boundaries for the tree\n",
        "  at given depth\n",
        "  depth : depth maximum where to fetch the lines\n",
        "  lim : the frame defined to plot the graph\n",
        "  node_n : node to fetch the lines\n",
        "  '''\n",
        "  seg = np.zeros((2,2))\n",
        "\n",
        "  if depth==-1:\n",
        "    return seg\n",
        "  else:\n",
        "    f = model.tree_.feature[node_n]\n",
        "\n",
        "    lc_node_n = model.tree_.children_left[node_n]\n",
        "    rc_node_n = model.tree_.children_right[node_n]\n",
        "\n",
        "    if f<0:\n",
        "      return seg\n",
        "    else:\n",
        "      thres = model.tree_.threshold[node_n]\n",
        "\n",
        "      seg[f,:] = thres\n",
        "      seg[1-f,:] = lim[1-f,:]\n",
        "\n",
        "      if (lc_node_n==-1) and (rc_node_n)==-1:\n",
        "        return seg\n",
        "      else:\n",
        "        l_lim = lim.copy()\n",
        "        r_lim = lim.copy()\n",
        "\n",
        "        l_lim[f, 1] = float(thres)\n",
        "        r_lim[f, 0] = float(thres)\n",
        "\n",
        "        seg = np.concatenate((seg, get_lines(depth-1, l_lim, lc_node_n)), axis=0) if not np.array_equal(get_lines(depth-1, l_lim, lc_node_n), np.zeros((2,2))) else seg\n",
        "        seg = np.concatenate((seg, get_lines(depth-1, r_lim, rc_node_n)), axis=0) if not np.array_equal(get_lines(depth-1, r_lim, rc_node_n), np.zeros((2,2))) else seg\n",
        "        return seg\n",
        "      \n",
        "    \n",
        "def get_decision_boundaries(depth, lim):\n",
        "  '''\n",
        "  Wrapper and formatter of the get_lines function\n",
        "  '''\n",
        "  segs = get_lines(depth, lim)\n",
        "  segments = []\n",
        "  for i in range(0,len(segs),2):\n",
        "    segments.append(segs[i:i+2,:])\n",
        "  return segments\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rQBfnjv1AVRp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_pred(feat, depth, node_n=0):\n",
        "  '''\n",
        "  Get the predictions of the decision tree at a given depth.\n",
        "  feat : coordinates (features) of the point\n",
        "  depth : depth at which the prediction is computed\n",
        "  node_n : node_n deciding the prediction\n",
        "  '''\n",
        "  f = model.tree_.feature[node_n]\n",
        "  # leaf\n",
        "  if f<0:\n",
        "    pred = np.argmax(model.tree_.value[node_n])\n",
        "    return pred\n",
        "  elif depth==0:\n",
        "    pred = np.argmax(model.tree_.value[node_n])\n",
        "    return pred\n",
        "  else:\n",
        "    if (feat[f]<=model.tree_.threshold[node_n]):\n",
        "      lc_node_n = model.tree_.children_left[node_n]\n",
        "      return get_pred(feat, depth-1, lc_node_n)\n",
        "    else:\n",
        "      rc_node_n = model.tree_.children_right[node_n]\n",
        "      return get_pred(feat, depth-1, rc_node_n)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eZk_NG3iAX7A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.style.use('seaborn-white')\n",
        "\n",
        "labels = iris['Species'].unique().tolist()\n",
        "plot_colors = 'ryb'\n",
        "plot_step = 0.02\n",
        "\n",
        "# We define a grid of points from which we will make predictions\n",
        "x_min, x_max = X_train.iloc[:, 0].min() - 1, X_train.iloc[:, 0].max() + 1\n",
        "y_min, y_max = X_train.iloc[:, 1].min() - 1, X_train.iloc[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
        "                     np.arange(y_min, y_max, plot_step))\n",
        "\n",
        "lim = np.array([[x_min, x_max-0.02],[y_min,y_max-0.05]])\n",
        "tree_depth = model.tree_.max_depth\n",
        "\n",
        "for i in range(tree_depth):\n",
        "    plt.figure(figsize=(10,40))\n",
        "    plt.subplot(tree_depth, 1, i+1)\n",
        "    \n",
        "    # Plot the background color which depicts the decision of the tree\n",
        "    Z = []\n",
        "    for feat in np.c_[xx.ravel(), yy.ravel()]:\n",
        "        Z.append(get_pred(feat,i))\n",
        "    Z[0]=1\n",
        "    Z = np.array(Z).reshape(xx.shape)\n",
        "    cs = plt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu, zorder=0)\n",
        "    \n",
        "    # Plot the boundaries of the decision tree\n",
        "    segments = get_decision_boundaries(i, lim)\n",
        "    for seg in segments:\n",
        "      plt.plot(seg[0,:], seg[1,:], 'k-')\n",
        "\n",
        "    # Plot the training data\n",
        "    for j, (species, color) in enumerate(zip(labels, plot_colors)):\n",
        "        idx = y_train.index[y_train==species]\n",
        "        plt.scatter(X_train.loc[idx][features[0]], X_train.loc[idx][features[1]], c=color, label=labels[j], cmap=plt.cm.RdYlBu, edgecolor='black', s=30, zorder=1)\n",
        "    \n",
        "    legend = plt.legend()\n",
        "    plt.xlabel(features[0])\n",
        "    plt.ylabel(features[1])\n",
        "    plt.title('Decision tree at depth {}'.format(i))\n",
        "    \n",
        "    \n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}